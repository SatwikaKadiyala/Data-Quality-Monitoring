# Data Quality Monitoring

  ## ğŸ“Œ Overview

    The Data Quality Monitoring project is a real-time distributed ETL pipeline designed to process high-volume stock market data efficiently.
    It integrates Apache Spark for parallel data processing, Apache Kafka for real-time data streaming, and PostgreSQL for storage,
    while leveraging Docker and Kubernetes for containerization and scalability.

    This system helps monitor data quality, detect anomalies, and trigger real-time alerts to ensure data reliability for analytics and reporting.

---

## âœ¨ Key Features

    * âš¡ Real-time ETL pipeline â€“ Processes high-volume streaming stock data.
    * ğŸ§© Distributed Computing â€“ Built with Apache Spark for parallel data processing.
    * ğŸ”” Real-time Alerts â€“ Uses Kafka for low-latency data streaming and anomaly detection.
    * ğŸ—„ï¸ Efficient Storage â€“ Stores processed data in PostgreSQL for downstream analytics.
    * ğŸ“Š Visualization Support â€“ Integrates with Power BI and Grafana dashboards for monitoring.
    * ğŸ³ Containerized Deployment â€“ Uses Docker and Kubernetes for scalable orchestration.

---

## ğŸ› ï¸ Tech Stack

    | Category         |   Technology      |
    | -----------------| ----------------- |
    | Programming      | Python 3.9+       |
    | Data Processing  | Apache Spark      |
    | Streaming        | Apache Kafka      |
    | Database         | PostgreSQL        |
    | Dashboarding     | Power BI, Grafana |
    | Containerization | Docker            |
    | Orchestration    | Kubernetes        |
    | Version Control  | Git & GitHub      |

---

## ğŸ“‚ Project Architecture

```mermaid
flowchart LR
    A[Stock Data Source] --> B[Kafka Producer]
    B --> C[Kafka Broker]
    C --> D[Spark Streaming Job]
    D --> E[PostgreSQL Database]
    E --> F[Power BI / Grafana Dashboards]
    D --> G[Anomaly Detection & Alerts]
```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/SatwikaKadiyala/Data-Quality-Monitoring.git
cd Data-Quality-Monitoring
```

### 2ï¸âƒ£ Set Up Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Start Kafka & Zookeeper

```bash
# Start Zookeeper
zookeeper-server-start.sh config/zookeeper.properties

# Start Kafka Broker
kafka-server-start.sh config/server.properties
```

### 5ï¸âƒ£ Start Spark Streaming Job

```bash
spark-submit \
  --master local[*] \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  src/etl_pipeline.py
```

### 6ï¸âƒ£ Run PostgreSQL Database

```bash
docker-compose up -d
```

### 7ï¸âƒ£ Deploy on Kubernetes

```bash
kubectl apply -f k8s/
```

---

## ğŸ“Š Dashboards

     * Power BI â†’ Visualizes processed stock data and monitors anomalies.
     * Grafana â†’ Tracks streaming metrics and real-time alerts.

---

## ğŸ“Œ Future Enhancements

    * âœ… Integrate Redis caching for faster reads.
    * âœ… Add machine learning anomaly detection models.
    * âœ… Improve fault tolerance and auto-recovery in Kubernetes.


